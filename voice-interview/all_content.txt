
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt
======================================================


C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt
======================================================


C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt
======================================================


C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\all_content.txt
======================================================


C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\a.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\config.js  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\config.js" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\config.js
======================================================

// config.js

// The 'export' keyword makes this constant available to other modules.
export const APP_CONFIG = {
    // Paste your Base64 encoded OpenAI API key here.
    // To encode: open browser console (F12) and run: btoa('your-real-api-key')
    encodedApiKey: 'c2stcHJvai01bHRPM3ZvX2pLaEEyWUowUlVDdld0Nlk0WjBLVEp2bzhjU2Ftb3VfVnl4WEN5U3RlWGR3bWZYQnIwRzBNbW13dGN3X1hDLXhOT1QzQmxia0ZKRVhPdWJDcWhvc0xLS3drTnRVZF9HWjBoN0FBQnVlTXRGQ0piY0xlNWJWWDJuVTZoZGNDWDZQQ0JCVEdUZGxTLTczc2R6NWU3QUE',

    // --- MODEL CONFIGURATION ---
    models: {
        transcription: {
            name: 'gpt-4o-mini-transcribe',
        },
        chat: {
            name: 'gpt-4.1-nano',
            // Pricing is per 1 Million tokens. Using gpt-4o-mini as a proxy for nano pricing.
            pricing: {
                input: 0.15 / 1_000_000,
                output: 0.60 / 1_000_000,
            },
            // Vision calculation rules based on your reference for gpt-4.1-nano
            vision: {
                patch_size: 32,
                token_budget: 1536,
                // The final number of patches is multiplied by this to get billable tokens.
                token_multiplier: 2.46, 
            }
        }
    },

    // --- SYSTEM PROMPT CONFIGURATION ---
    // The prompt is now a function to allow dynamic injection of state variables.
        systemPrompt: (additionalDetails, cvContent) => `You are an expert interview coach acting as the user. Your goal is to provide natural, confident, and concise answers to interview questions. Make sure that the language of the answers is not very difficult. Moderate the answers to the level of 6 Bands in IELTS or CEFR Level B2

        *YOUR PERSONA:*
        - You are the candidate. Always speak in the first person ("I", "my", "we").
        - Your tone should be professional yet conversational and personable. Avoid robotic language and excessive jargon. Do not use very high vocabulary words like passion, passionate, embark etc. Keep it simple
        - You are confident but humble.


        *YOUR TASK:*
        1.  Analyze the interviewer's question provided by the user, which may be about text or an attached image.
        2.  Formulate a high-quality answer based on the provided "CV Content," "Additional Context," and any image content.
        3.  If the question is completely unrelated to a professional interview (e.g., "What did you have for breakfast?", "What's your favorite movie?"), provide a brief, natural, and positive placeholder answer. Do not say you don't know or that it's not in the CV. Just answer it like a normal person would.
        4.  Keep answers concise and impactful, typically 3-5 sentences.
        **REFERENCE MATERIAL:**

        ---
        **ADDITIONAL CONTEXT (Job Description, Company Info, etc.):**
        ${additionalDetails}
        ---
        **CV CONTENT:**
        ${cvContent}
        ---`
};
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\directory_listing.txt  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\directory_listing.txt" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\directory_listing.txt
======================================================

Folder PATH listing
Volume serial number is DE49-F054
C:.
³   a.txt
³   config.js
³   directory_listing.txt
³   index.html
³   style.css
³   
ÀÄÄÄjs
        api.js
        main.js
        recorder.js
        state.js
        ui.js
        

C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\index.html  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\index.html" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\index.html
======================================================

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Interview Assistant</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css">
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div class="main-content" id="mainContent">
        <div id="conversation">
            <!-- Messages appear here -->
        </div>
    </div>
    
    <div id="teleprompter" style="display: none;">
        <div id="teleprompterContent"></div>
        <button id="teleprompterCloseBtn">Ã—</button>
    </div>

    <div class="control-panel" id="controlPanel">
        <div class="panel-header" id="panelToggle">
            <span>Controls & Setup</span>
            <i class="fas fa-chevron-left toggle-icon"></i>
        </div>
        
        <div class="panel-content" id="setupSection">
            <div class="input-group">
                <label for="apiKey">OpenAI API Key</label>
                <input type="password" id="apiKey" placeholder="Loaded from config.js or enter here" />
            </div>
            <div class="input-group">
                <label for="additionalDetails">Context (Job Description, Company Info)</label>
                <textarea id="additionalDetails" rows="3" placeholder="Paste key context here..."></textarea>
            </div>
            <div class="input-group">
                <label for="cvContent">Your CV / Resume</label>
                <textarea id="cvContent" rows="7" placeholder="Paste your full CV content here..."></textarea>
            </div>
        </div>

        <div class="main-controls">
            <!-- RESTORED a clear, stable button flow -->
            <button class="record-btn" id="recordMicBtn" disabled><i class="fas fa-microphone"></i> Record Mic</button>
            <button class="record-btn" id="connectTabBtn" disabled><i class="fas fa-desktop"></i> Connect Tab</button>
            <button class="record-btn" id="recordTabAudioBtn" style="display: none;"><i class="fas fa-volume-high"></i> Record Tab Audio</button>
            <button class="record-btn stop-btn" id="stopBtn" style="display: none;"><i class="fas fa-stop"></i> Stop Recording</button>
        </div>

        <div class="status-footer">
             <div class="status" id="status">Enter details to begin</div>
             <div class="cost-tracker" id="costTracker">Cost: $0.00000</div>
        </div>
    </div>

    <script type="module" src="js/main.js"></script>
</body>
</html>
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo. 
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\style.css  
 echo ======================================================  
 echo. 
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\style.css" 
) 

======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\style.css
======================================================

/* Reset and Base Styles */
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
    background-color: #0f0f0f;
    color: #e5e5e5;
    line-height: 1.6;
    height: 100vh;
    display: flex;
    flex-direction: column;
}

/* Main Content Area */
.main-content {
    flex: 1;
    padding: 2rem;
    overflow-y: auto;
    background-color: #1a1a1a;
    border-right: 1px solid #2d2d2d;
    margin-right: 380px;
    transition: margin-right 0.3s ease;
}

.main-content.expanded {
    margin-right: 40px;
}

/* Message Styling */
.message {
    margin-bottom: 1.5rem;
    padding: 1rem;
    border-radius: 8px;
    max-width: 100%;
}

.message.user {
    background-color: #262626;
    border-left: 3px solid #3b82f6;
}

.message.assistant {
    background-color: #1f1f1f;
    border: 1px solid #2d2d2d;
    border-left: 3px solid #10b981;
}

.message-content {
    font-size: 0.95rem;
    line-height: 1.6;
}

.message-timestamp {
    font-size: 0.8rem;
    color: #9ca3af;
    margin-top: 0.5rem;
}

/* AI Suggestions Display */
#teleprompter {
    position: fixed;
    top: 0;
    left: 0;
    right: 380px;
    bottom: 0;
    background-color: rgba(0, 0, 0, 0.95);
    z-index: 500;
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 2rem;
    transition: right 0.3s ease;
}

#teleprompter.expanded {
    right: 40px;
}

#teleprompterContent {
    background-color: #1a1a1a;
    color: #e5e5e5;
    padding: 3rem;
    border-radius: 12px;
    border: 1px solid #2d2d2d;
    max-width: 800px;
    width: 100%;
    font-size: 1.5rem;
    line-height: 1.8;
    text-align: center;
}

#teleprompterCloseBtn {
    position: absolute;
    top: 2rem;
    right: 2rem;
    background: none;
    border: none;
    color: #e5e5e5;
    font-size: 2rem;
    cursor: pointer;
    width: 40px;
    height: 40px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 50%;
    transition: background-color 0.2s;
}

#teleprompterCloseBtn:hover {
    background-color: rgba(255, 255, 255, 0.1);
}

.ai-suggestion {
    background-color: #1e293b;
    border: 1px solid #0ea5e9;
    border-radius: 8px;
    padding: 1.5rem;
    margin-bottom: 1rem;
    font-size: 1.1rem;
    line-height: 1.7;
    color: #38bdf8;
}

.ai-suggestion.active {
    background-color: #0f172a;
    border-color: #0284c7;
    box-shadow: 0 2px 8px rgba(2, 132, 199, 0.2);
}

.suggestion-header {
    font-weight: 600;
    margin-bottom: 0.5rem;
    color: #38bdf8;
    font-size: 0.9rem;
    text-transform: uppercase;
    letter-spacing: 0.5px;
}

/* Control Panel Sidebar */
.control-panel {
    position: fixed;
    top: 0;
    right: 0;
    height: 100vh;
    width: 380px;
    background-color: #1a1a1a;
    border-left: 1px solid #2d2d2d;
    display: flex;
    flex-direction: column;
    z-index: 100;
    transform: translateX(0);
    transition: transform 0.3s ease;
}

.control-panel.collapsed {
    transform: translateX(340px);
}

/* Panel Header */
.panel-header {
    padding: 1rem 1.5rem;
    border-bottom: 1px solid #2d2d2d;
    background-color: #262626;
    display: flex;
    align-items: center;
    justify-content: space-between;
    cursor: pointer;
    user-select: none;
    font-weight: 500;
    font-size: 0.9rem;
    color: #e5e5e5;
}

.panel-header:hover {
    background-color: #2d2d2d;
}

.toggle-icon {
    transition: transform 0.3s ease;
}

.control-panel.collapsed .toggle-icon {
    transform: rotate(180deg);
}

/* Panel Content */
.panel-content {
    flex: 1;
    padding: 1.5rem;
    overflow-y: auto;
    opacity: 1;
    transition: opacity 0.3s ease;
}

.control-panel.collapsed .panel-content {
    opacity: 0;
    pointer-events: none;
}

/* Input Groups */
.input-group {
    margin-bottom: 1.5rem;
}

.input-group label {
    display: block;
    margin-bottom: 0.5rem;
    font-weight: 500;
    font-size: 0.9rem;
    color: #e5e5e5;
}

.input-group input,
.input-group textarea {
    width: 100%;
    padding: 0.75rem;
    border: 1px solid #404040;
    border-radius: 6px;
    font-size: 0.9rem;
    transition: border-color 0.2s, box-shadow 0.2s;
    background-color: #262626;
    color: #e5e5e5;
}

.input-group input:focus,
.input-group textarea:focus {
    outline: none;
    border-color: #3b82f6;
    box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
}

.input-group input::placeholder,
.input-group textarea::placeholder {
    color: #9ca3af;
}

.input-group textarea {
    resize: vertical;
    min-height: 60px;
}

/* Main Controls */
.main-controls {
    padding: 1.5rem;
    border-top: 1px solid #2d2d2d;
    background-color: #262626;
    opacity: 1;
    transition: opacity 0.3s ease;
}

.control-panel.collapsed .main-controls {
    opacity: 0;
    pointer-events: none;
}

.record-btn {
    width: 100%;
    padding: 0.875rem 1rem;
    border: none;
    border-radius: 6px;
    font-size: 0.9rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.5rem;
    margin-bottom: 0.75rem;
    background-color: #3b82f6;
    color: #ffffff;
}

.record-btn:hover:not(:disabled) {
    background-color: #2563eb;
    transform: translateY(-1px);
}

.record-btn:disabled {
    background-color: #404040;
    color: #9ca3af;
    cursor: not-allowed;
    transform: none;
}

.record-btn.stop-btn {
    background-color: #dc2626;
}

.record-btn.stop-btn:hover {
    background-color: #b91c1c;
}

.record-btn i {
    font-size: 1rem;
}

/* Status */
.status {
    text-align: center;
    padding: 0.75rem;
    border-radius: 6px;
    font-size: 0.85rem;
    font-weight: 500;
    background-color: #262626;
    color: #9ca3af;
    border: 1px solid #404040;
}

.status.recording {
    background-color: #451a03;
    color: #fbbf24;
    border-color: #92400e;
}

.status.processing {
    background-color: #1e3a8a;
    color: #93c5fd;
    border-color: #3b82f6;
}

.status.error {
    background-color: #7f1d1d;
    color: #fca5a5;
    border-color: #dc2626;
}

/* Responsive Design */
@media (max-width: 768px) {
    .main-content {
        margin-right: 0;
        margin-bottom: 0;
        padding: 1rem;
    }
    
    .main-content.expanded {
        margin-right: 0;
    }
    
    .control-panel {
        width: 100%;
        height: auto;
        position: fixed;
        bottom: 0;
        top: auto;
        transform: translateY(0);
        border-left: none;
        border-top: 1px solid #2d2d2d;
    }
    
    .control-panel.collapsed {
        transform: translateY(calc(100% - 60px));
    }
    
    .panel-content {
        max-height: 50vh;
        overflow-y: auto;
    }
    
    body {
        padding-bottom: 60px;
    }
    
    .control-panel.collapsed ~ .main-content {
        padding-bottom: 1rem;
    }
    
    /* Mobile teleprompter adjustments */
    #teleprompter {
        right: 0;
        bottom: 60px;
    }
    
    #teleprompter.expanded {
        right: 0;
        bottom: 60px;
    }
    
    .control-panel.collapsed ~ #teleprompter {
        bottom: 60px;
    }
}

/* Scrollbar Styling */
::-webkit-scrollbar {
    width: 6px;
}

::-webkit-scrollbar-track {
    background: #262626;
}

::-webkit-scrollbar-thumb {
    background: #404040;
    border-radius: 3px;
}

::-webkit-scrollbar-thumb:hover {
    background: #525252;
}

/* Animation for smooth interactions */
@keyframes fadeIn {
    from {
        opacity: 0;
        transform: translateY(10px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

.message {
    animation: fadeIn 0.3s ease-out;
}

/* Loading states */
.loading {
    position: relative;
    overflow: hidden;
}

.loading::after {
    content: '';
    position: absolute;
    top: 0;
    left: -100%;
    width: 100%;
    height: 100%;
    background: linear-gradient(90deg, transparent, rgba(255, 255, 255, 0.1), transparent);
    animation: loading 1.5s infinite;
}

@keyframes loading {
    0% {
        left: -100%;
    }
    100% {
        left: 100%;
    }
}

/* Focus indicators for accessibility */
button:focus-visible,
input:focus-visible,
textarea:focus-visible {
    outline: 2px solid #3b82f6;
    outline-offset: 2px;
}

/* Collapsed state indicator */
.control-panel.collapsed .panel-header {
    writing-mode: vertical-lr;
    text-orientation: mixed;
    width: 40px;
    height: 100%;
    padding: 1rem 0.5rem;
    border-bottom: none;
    border-left: 1px solid #2d2d2d;
}

.control-panel.collapsed .panel-header span {
    font-size: 0.8rem;
}

/* JavaScript will handle the collapsing functionality */
.js-panel-toggle {
    cursor: pointer;
}
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo..  
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\api.js  
 echo ======================================================  
 echo..  
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\api.js" 
) 
.
======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\api.js
======================================================
.
// js/api.js
import { state } from './state.js';
import * as ui from './ui.js';
import { APP_CONFIG } from '../config.js';

const CHAT_MODEL_CONFIG = APP_CONFIG.models.chat;

function calculateImageTokens(width, height) {
    const { patch_size, token_budget, token_multiplier } = CHAT_MODEL_CONFIG.vision;
    let w = width, h = height;
    let patches_w = Math.ceil(w / patch_size);
    let patches_h = Math.ceil(h / patch_size);

    if (patches_w * patches_h > token_budget) {
        const shrink_factor = Math.sqrt((token_budget * (patch_size ** 2)) / (w * h));
        w = Math.floor(w * shrink_factor);
        h = Math.floor(h * shrink_factor);
        const temp_patches_w = Math.ceil(w / patch_size);
        const final_scale = (temp_patches_w - 1) / temp_patches_w;
        w = Math.floor(w * final_scale);
        h = Math.floor(h * final_scale);
        patches_w = Math.ceil(w / patch_size);
        patches_h = Math.ceil(h / patch_size);
    }
    
    const total_patches = patches_w * patches_h;
    return total_patches * token_multiplier;
}

export function calculateCost(inputTokens, outputTokens = 0) {
    const pricing = CHAT_MODEL_CONFIG.pricing;
    if (!pricing) return { inputTokens, outputTokens, cost: 0 };
    const inputCost = inputTokens * pricing.input;
    const outputCost = outputTokens * pricing.output;
    return { inputTokens, outputTokens, cost: inputCost + outputCost };
}

export async function transcribeAudio(audioBlob) {
    ui.setStatus('Transcribing...', 'processing');
    const formData = new FormData();
    formData.append('file', audioBlob, 'interview_audio.webm');
    formData.append('model', APP_CONFIG.models.transcription.name);

    try {
        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
            method: 'POST',
            headers: { 'Authorization': `Bearer ${state.apiKey}` },
            body: formData,
        });
        const data = await response.json();
        if (!response.ok) throw new Error(data.error?.message || `API Error: ${response.status}`);
        return data.text;
    } catch (error) {
        ui.showError(`Transcription failed: ${error.message}`);
        return null;
    }
}

// --- THIS FUNCTION IS NOW MORE ROBUST ---
async function handleStream(response, onStreamStart, onStreamUpdate, onStreamEnd) {
    const reader = response.body.getReader();
    const decoder = new TextDecoder();
    
    onStreamStart();

    let outputText = '';
    while (true) {
        const { done, value } = await reader.read();
        if (done) break;
        
        const chunk = decoder.decode(value);
        const lines = chunk.split('\n').filter(line => line.trim() !== '');
        for (const line of lines) {
            if (line.startsWith('data: ')) {
                const data = line.substring(6);
                
                // THE FIX IS HERE: Don't try to parse [DONE] or empty data chunks
                if (data === '[DONE]') {
                    onStreamEnd(outputText);
                    return;
                }
                if (data.trim() === '') {
                    continue;
                }
                
                try {
                    const json = JSON.parse(data);
                    const content = json.choices[0]?.delta?.content || '';
                    if (content) {
                        outputText += content;
                        onStreamUpdate(content);
                    }
                } catch (e) {
                    console.error('Error parsing stream data:', e, 'Data chunk:', data);
                }
            }
        }
    }
     onStreamEnd(outputText);
}

export async function getAIResponseStream(transcribedText, { onStreamStart, onStreamUpdate, onStreamEnd }) {
    ui.showTyping();
    try {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: { 'Authorization': `Bearer ${state.apiKey}`, 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: CHAT_MODEL_CONFIG.name,
                messages: [
                    { role: 'system', content: APP_CONFIG.systemPrompt(state.additionalDetails, state.cvContent) },
                    { role: 'user', content: transcribedText }
                ],
                stream: true,
            }),
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error.message);
        }
        await handleStream(response, onStreamStart, onStreamUpdate, onStreamEnd);
    } catch (error) {
        ui.showError(`AI response failed: ${error.message}`);
    }
}

export async function getVisionResponseStream(textPrompt, image, { onStreamStart, onStreamUpdate, onStreamEnd }) {
    ui.showTyping();
    try {
        const imageInputTokens = calculateImageTokens(image.width, image.height);
        
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: { 'Authorization': `Bearer ${state.apiKey}`, 'Content-Type': 'application/json' },
            body: JSON.stringify({
                model: CHAT_MODEL_CONFIG.name,
                messages: [
                    { role: 'system', content: APP_CONFIG.systemPrompt(state.additionalDetails, state.cvContent) },
                    { role: 'user', content: [{ type: 'text', text: textPrompt }, { type: 'image_url', image_url: { url: image.base64, detail: 'high' } }] }
                ],
                max_tokens: 1024,
                stream: true,
            }),
        });

        if (!response.ok) {
            const errorData = await response.json();
            throw new Error(errorData.error.message);
        }
        
        const startCallback = () => onStreamStart(imageInputTokens);
        await handleStream(response, startCallback, onStreamUpdate, onStreamEnd);
    } catch (error) {
        ui.showError(`Vision request failed: ${error.message}`);
    }
}
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo..  
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\main.js  
 echo ======================================================  
 echo..  
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\main.js" 
) 
.
======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\main.js
======================================================
.
// js/main.js
import { state } from './state.js';
import * as ui from './ui.js';
import * as recorder from './recorder.js';
import * as api from './api.js';
import { APP_CONFIG } from '../config.js';

const STORAGE_KEYS = { CV: 'interviewAssistant_cvContent', DETAILS: 'interviewAssistant_additionalDetails' };
function saveToStorage(key, value) { try { localStorage.setItem(key, value); } catch (e) { console.error("Failed to save to local storage:", e); } }
function loadFromStorage(key) { try { return localStorage.getItem(key) || ''; } catch (e) { console.error("Failed to load from local storage:", e); return ''; } }

async function processRecording(audioBlob) {
    const transcribedText = await api.transcribeAudio(audioBlob);
    if (transcribedText && transcribedText.trim()) {
        ui.addMessage(transcribedText, true);
        let streamableMessageElement;
        await api.getAIResponseStream(transcribedText, {
            onStreamStart: () => { streamableMessageElement = ui.createStreamableMessage(); ui.showTeleprompter(); },
            onStreamUpdate: (chunk) => { ui.appendToMessage(streamableMessageElement, chunk); ui.appendToTeleprompter(chunk); },
            onStreamEnd: (fullText) => {
                const inputTokens = Math.ceil(transcribedText.length / 4);
                const outputTokens = Math.ceil(fullText.length / 4);
                const costData = api.calculateCost(inputTokens, outputTokens);
                state.totalCost += costData.cost;
                ui.updateTotalCostDisplay(state.totalCost);
                ui.addCostToMessage(streamableMessageElement, costData);
                ui.updateButtonStates();
            }
        });
    } else if (transcribedText !== null) {
        ui.showError('No speech was detected in the audio.');
        ui.updateButtonStates();
    }
}

function handleSetupInput() {
    const elements = ui.getElements();
    if (!elements.apiKeyInput.disabled) { state.apiKey = elements.apiKeyInput.value.trim(); }
    state.cvContent = elements.cvInput.value.trim();
    state.additionalDetails = elements.additionalDetailsInput.value.trim();
    saveToStorage(STORAGE_KEYS.CV, state.cvContent);
    saveToStorage(STORAGE_KEYS.DETAILS, state.additionalDetails);
    ui.updateButtonStates();
}

function initialize() {
    const elements = ui.getElements();

    if (APP_CONFIG?.encodedApiKey && APP_CONFIG.encodedApiKey !== 'PASTE_YOUR_ENCODED_API_KEY_HERE') {
        try {
            state.apiKey = atob(APP_CONFIG.encodedApiKey);
            elements.apiKeyInput.value = '********';
            elements.apiKeyInput.disabled = true;
        } catch (e) { ui.showError("Invalid API key in config.js."); }
    }

    state.cvContent = loadFromStorage(STORAGE_KEYS.CV);
    state.additionalDetails = loadFromStorage(STORAGE_KEYS.DETAILS);
    elements.cvInput.value = state.cvContent;
    elements.additionalDetailsInput.value = state.additionalDetails;

    // --- UPDATED EVENT LISTENERS ---
    elements.apiKeyInput.addEventListener('input', handleSetupInput);
    elements.cvInput.addEventListener('input', handleSetupInput);
    elements.additionalDetailsInput.addEventListener('input', handleSetupInput);
    
    elements.recordMicBtn.addEventListener('click', () => recorder.startRecording('mic', processRecording));
    elements.connectTabBtn.addEventListener('click', recorder.connectToTab); // Connects the tab
    elements.recordTabAudioBtn.addEventListener('click', () => recorder.startRecording('tab-audio', processRecording)); // Records from connected tab

    elements.stopBtn.addEventListener('click', recorder.stopRecording);
    elements.panelToggle.addEventListener('click', ui.toggleSetupPanel);
    elements.teleprompterCloseBtn.addEventListener('click', ui.hideTeleprompter);

    handleSetupInput();
    ui.updateTotalCostDisplay(state.totalCost);
}

initialize();
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo..  
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\recorder.js  
 echo ======================================================  
 echo..  
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\recorder.js" 
) 
.
======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\recorder.js
======================================================
.
// js/recorder.js
import { state } from './state.js';
import * as ui from './ui.js';

// --- NEW DEDICATED CONNECT FUNCTION ---
export async function connectToTab() {
    if (state.isRecording || state.isTabConnected) return;
    ui.setStatus('Select tab to connect...', 'processing');

    try {
        const displayStream = await navigator.mediaDevices.getDisplayMedia({
            video: true,
            audio: true
        });

        if (displayStream.getAudioTracks().length === 0) {
            ui.showError("No audio found. Ensure you checked 'Share tab audio'.");
            displayStream.getTracks().forEach(track => track.stop());
            return;
        }

        const audioTrack = displayStream.getAudioTracks()[0];
        state.persistentTabStream = new MediaStream([audioTrack]);
        state.isTabConnected = true;

        // When the user manually stops sharing via the browser UI
        audioTrack.onended = () => {
            state.isTabConnected = false;
            state.persistentTabStream = null;
            ui.updateButtonStates();
        };
        
        // Stop the video track immediately as we don't need it for audio recording
        displayStream.getVideoTracks().forEach(track => track.stop());

        ui.updateButtonStates();

    } catch(error) {
        ui.showError(`Could not connect to tab: ${error.message}`);
        ui.updateButtonStates();
    }
}


export async function startRecording(sourceType, onStopCallback) {
    if (state.isRecording) return;
    
    let stream;
    if (sourceType === 'mic') {
        stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    } else if (sourceType === 'tab-audio') {
        if (!state.isTabConnected || !state.persistentTabStream) {
            ui.showError("Tab audio not connected.");
            return;
        }
        stream = state.persistentTabStream;
    } else {
        ui.showError("Unknown recording source.");
        return;
    }

    if (!stream) {
        ui.showError("Failed to get audio stream.");
        return;
    }

    state.isRecording = true;
    state.currentSource = sourceType === 'mic' ? 'Mic' : 'Tab Audio';
    state.audioChunks = [];
    ui.updateButtonStates();

    state.mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
    
    state.mediaRecorder.ondataavailable = event => {
        if (event.data.size > 0) state.audioChunks.push(event.data);
    };

    state.mediaRecorder.onstop = () => {
        const audioBlob = new Blob(state.audioChunks, { type: 'audio/webm' });
        if (audioBlob.size > 100 && onStopCallback) {
            onStopCallback(audioBlob);
        } else if (audioBlob.size <= 100) {
            ui.showError('No audio was recorded.');
            ui.updateButtonStates();
        }
        // IMPORTANT: Only stop tracks if it's a mic recording.
        if (sourceType === 'mic') {
            stream.getTracks().forEach(track => track.stop());
        }
    };

    state.mediaRecorder.start();
}

export function stopRecording() {
    if (!state.isRecording || !state.mediaRecorder) return;
    state.mediaRecorder.stop();
    state.isRecording = false;
    ui.setStatus('Processing...', 'processing');
}
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo..  
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\state.js  
 echo ======================================================  
 echo..  
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\state.js" 
) 
.
======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\state.js
======================================================
.
// js/state.js
export const state = {
    apiKey: '',
    cvContent: '',
    additionalDetails: '',
    isRecording: false,
    // --- ADDED BACK for persistent connection ---
    isTabConnected: false,
    persistentTabStream: null,
    // ------------------------------------------
    mediaRecorder: null,
    audioChunks: [],
    currentSource: null,
    totalCost: 0.0,
};
C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview>(
echo..  
 echo ======================================================  
 echo FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\ui.js  
 echo ======================================================  
 echo..  
 type "C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\ui.js" 
) 
.
======================================================
FILE: C:\Users\MSI\Desktop\harsh\harshkgpian.github.io\voice-interview\js\ui.js
======================================================
.
// js/ui.js
import { state } from './state.js';

const elements = {
    mainContent: document.getElementById('mainContent'),
    controlPanel: document.getElementById('controlPanel'),
    conversation: document.getElementById('conversation'),
    
    // Updated button references
    recordMicBtn: document.getElementById('recordMicBtn'),
    connectTabBtn: document.getElementById('connectTabBtn'),
    recordTabAudioBtn: document.getElementById('recordTabAudioBtn'),
    stopBtn: document.getElementById('stopBtn'),
    
    teleprompter: document.getElementById('teleprompter'),
    teleprompterContent: document.getElementById('teleprompterContent'),
    teleprompterCloseBtn: document.getElementById('teleprompterCloseBtn'),
    
    panelToggle: document.getElementById('panelToggle'),
    apiKeyInput: document.getElementById('apiKey'),
    cvInput: document.getElementById('cvContent'),
    additionalDetailsInput: document.getElementById('additionalDetails'),
    
    status: document.getElementById('status'),
    costTracker: document.getElementById('costTracker'),
};

export function getElements() { return elements; }

export function updateButtonStates() {
    const { isRecording, isTabConnected, apiKey, cvContent } = state;
    const isReady = apiKey && cvContent;

    if (isRecording) {
        // Hide all action buttons when recording
        elements.recordMicBtn.style.display = 'none';
        elements.connectTabBtn.style.display = 'none';
        elements.recordTabAudioBtn.style.display = 'none';
        elements.stopBtn.style.display = 'inline-block';
        setStatus(`Recording ${state.currentSource}...`, 'recording');
    } else {
        // Show action buttons, hide stop button
        elements.stopBtn.style.display = 'none';
        elements.recordMicBtn.style.display = 'inline-block';
        
        // Logic for tab buttons
        if (isTabConnected) {
            elements.connectTabBtn.style.display = 'none';
            elements.recordTabAudioBtn.style.display = 'inline-block';
        } else {
            elements.connectTabBtn.style.display = 'inline-block';
            elements.recordTabAudioBtn.style.display = 'none';
        }

        // Set disabled state
        elements.recordMicBtn.disabled = !isReady;
        elements.connectTabBtn.disabled = !isReady;
        elements.recordTabAudioBtn.disabled = !isReady;

        if (!isReady) {
            setStatus('Enter details to begin', 'normal');
        } else {
            setStatus('Ready to record or connect tab.', 'normal');
        }
    }
}



export function updateTotalCostDisplay(totalCost) {
    elements.costTracker.textContent = `Cost: $${totalCost.toFixed(5)}`;
}

export function addCostToMessage(messageElement, costData) {
    if (!messageElement || !costData) return;
    const costDiv = document.createElement('div');
    costDiv.className = 'message-timestamp';
    costDiv.textContent = `Tokens: ${costData.inputTokens} | Cost: ~$${costData.cost.toFixed(5)}`;
    messageElement.appendChild(costDiv);
}

export function toggleSetupPanel() {
    elements.controlPanel.classList.toggle('collapsed');
    elements.mainContent.classList.toggle('expanded');
    elements.teleprompter.classList.toggle('expanded');
}

export function showTeleprompter(initialText = '') {
    elements.teleprompterContent.textContent = initialText;
    elements.teleprompter.style.display = 'flex';
}

export function appendToTeleprompter(text) { elements.teleprompterContent.textContent += text; }

export function hideTeleprompter() { elements.teleprompter.style.display = 'none'; }

export function createStreamableMessage() {
    const messageContainer = document.createElement('div');
    messageContainer.className = 'message assistant';
    
    const contentDiv = document.createElement('div');
    contentDiv.className = 'message-content';
    messageContainer.appendChild(contentDiv);

    elements.conversation.appendChild(messageContainer);
    return messageContainer;
}

export function appendToMessage(element, text) {
    if (element) {
        const contentDiv = element.querySelector('.message-content');
        if(contentDiv) contentDiv.textContent += text;
    }
}

export function addMessage(text, isUser = false) {
    const messageDiv = document.createElement('div');
    messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
    messageDiv.innerHTML = `<div class="message-content">${text}</div>`;
    elements.conversation.appendChild(messageDiv);
}

export function showError(message) {
    setStatus(message, 'error');
}

export function setStatus(text, type = 'normal') {
    elements.status.textContent = text;
    elements.status.className = `status ${type}`;
}

export function showTyping() { setStatus('Assistant is thinking...', 'processing'); }